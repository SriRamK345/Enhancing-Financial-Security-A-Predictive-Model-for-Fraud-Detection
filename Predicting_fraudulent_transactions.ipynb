{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1PJABJW_9cVqwZFDl_ukv6fkH8pBQtHMp",
      "authorship_tag": "ABX9TyNr1Flc+Mr3G5B7w65omF+3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SriRamK345/Enhancing-Financial-Security-A-Predictive-Model-for-Fraud-Detection/blob/main/Predicting_fraudulent_transactions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Features:**\n",
        "\n",
        "* **step:** Represents a unit of time, where 1 step equals 1 hour. This means the simulation spans 744 steps (30 days * 24 hours/day).\n",
        "* **type:** Categorical variable indicating the transaction type:\n",
        "    * CASH-IN\n",
        "    * CASH-OUT\n",
        "    * DEBIT\n",
        "    * PAYMENT\n",
        "    * TRANSFER\n",
        "* **amount:** Numerical value representing the transaction amount in the local currency.\n",
        "* **nameOrig:** Customer who initiated the transaction.\n",
        "* **oldbalanceOrg:** Initial balance of the originator's account before the transaction.\n",
        "* **newbalanceOrig:** Updated balance of the originator's account after the transaction.\n",
        "* **nameDest:** Recipient of the transaction (if applicable). Note: Missing for merchants starting with \"M\".\n",
        "* **oldbalanceDest:** Initial balance of the recipient's account before the transaction (if applicable). Missing for merchants starting with \"M\".\n",
        "* **newbalanceDest:** Updated balance of the recipient's account after the transaction (if applicable). Missing for merchants starting with \"M\".\n",
        "* **isFraud:** This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system..\n",
        "* **isFlaggedFraud:** The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction."
      ],
      "metadata": {
        "id": "GD6uoKQbavLV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oxyhkz0WbHRf"
      },
      "outputs": [],
      "source": [
        "# Data cleaning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Visualization / EDA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# remove warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading datasets"
      ],
      "metadata": {
        "id": "agKk6vpceqM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Predicting fraudulent transactions/Fraud.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "v7MV6G7zbg51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysing Datasets"
      ],
      "metadata": {
        "id": "rlQ4SD5ncSXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "XGfg_q8DcSoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of rows :\",len(df))\n",
        "print(\"number of columns :\",len(df.columns))"
      ],
      "metadata": {
        "id": "8dYZMiwpcVEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_duplicates = df.duplicated().sum()\n",
        "total_rows = len(df)\n",
        "percentage_duplicates = (num_duplicates / total_rows) * 100\n",
        "print(f\"Percentage of duplicate values: {percentage_duplicates:.2f}%\")"
      ],
      "metadata": {
        "id": "EpVpoAPtjGAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Checking Null Values"
      ],
      "metadata": {
        "id": "nnxHsJZ3fjJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "emPMxxxab1Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "per_null = df.isna().sum()/len(df)*100\n",
        "print(f\"percentage of missing data {per_null}\")"
      ],
      "metadata": {
        "id": "N8Qav8RRb1Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ApSvz5Yaqn2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"isFraud\"].value_counts()"
      ],
      "metadata": {
        "id": "5thtAcQsqn_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"isFlaggedFraud\"].value_counts()"
      ],
      "metadata": {
        "id": "SJnQIWblq987"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "iK5tmF26tYya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unique Values"
      ],
      "metadata": {
        "id": "vTGQT-BOZMEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_number = []\n",
        "for i in df.columns:\n",
        "    x = df[i].value_counts().count()\n",
        "    unique_number.append(x)\n",
        "\n",
        "pd.DataFrame(unique_number, index = df.columns, columns = [\"Total Unique Values\"])"
      ],
      "metadata": {
        "id": "j10FevErZMKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis(EDA)"
      ],
      "metadata": {
        "id": "iKdermrSc6HD"
      }
    },
    {
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "isFraud_counts = df[\"isFraud\"].value_counts()\n",
        "labels = isFraud_counts.index\n",
        "sizes = isFraud_counts.values\n",
        "\n",
        "# Create pie chart\n",
        "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "plt.title(\"Distribution of Fraud\")\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FjU0CSnurfTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df, x='type',palette = \"Set2\")\n",
        "plt.xlabel(\"Transaction Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Transaction Types\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7oNTUo38b1Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=df, x='type', hue='isFraud', palette=\"Set2\")\n",
        "plt.xlabel(\"Transaction Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Transaction Types by Fraud\")\n",
        "plt.legend(title=\"Is Fraud\", loc=\"upper right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yPBzXUPOaBtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "droRragSaq2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_=df.copy()"
      ],
      "metadata": {
        "id": "tsVIgiDQvR6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check object datatypes\n",
        "obj = df_.select_dtypes(include = \"object\").columns\n",
        "print(obj)"
      ],
      "metadata": {
        "id": "TtbCRx3wX3N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding"
      ],
      "metadata": {
        "id": "QGxD-hK_S2pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "7U6ejKcyunJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode the objects\n",
        "le = LabelEncoder()\n",
        "\n",
        "for i in obj:\n",
        "    df_[i] = le.fit_transform(df_[i].astype(str))\n",
        "\n",
        "print(df_.info())"
      ],
      "metadata": {
        "id": "_20JipRYujf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for correlation\n",
        "corr = df_.corr(numeric_only=True)\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(corr , annot =True)"
      ],
      "metadata": {
        "id": "ESUJsgum05TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variation inflation factor"
      ],
      "metadata": {
        "id": "OSTTpCNp92tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ],
      "metadata": {
        "id": "xZyB_7eQ1FbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to find the variation inflation factor\n",
        "def cal_vif(df):\n",
        "    vif = pd.DataFrame()\n",
        "    vif['variables'] = df.columns\n",
        "    vif['VIF'] = [variance_inflation_factor(df.values,i) for i in range(df.shape[1])]\n",
        "    return vif\n",
        "\n",
        "cal_vif(df_)"
      ],
      "metadata": {
        "id": "fdVRs4C01B98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling"
      ],
      "metadata": {
        "id": "AW3g3u1Zv4Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"isFraud\"].value_counts()"
      ],
      "metadata": {
        "id": "5zvt3e3hwOBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Separate majority and minority classes\n",
        "df_majority = df_[df_['isFraud'] == 0]\n",
        "df_minority = df_[df_['isFraud'] == 1]\n",
        "\n",
        "# Downsample the majority class to 25000 samples\n",
        "df_majority_downsampled = df_majority.sample(n=25000, random_state=42)\n",
        "\n",
        "# Oversample\n",
        "df_minority_oversample = df_minority.sample(n=20000, random_state=42, replace=True)\n",
        "\n",
        "# Combine\n",
        "df_balanced = pd.concat([df_majority_downsampled, df_minority_oversample])\n",
        "\n",
        "# Shuffle the balanced dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"Balanced Class Distribution:\")\n",
        "print(df_balanced['isFraud'].value_counts())"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "RNFGc69PxGQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA\n",
        "\n",
        "PCA creates uncorrelated principal components, which can be helpful for certain machine learning algorithms that assume feature independence. In your code, you observed high correlation between features such as `oldbalanceOrg`, `newbalanceOrig`, `oldbalanceDest`, and `newbalanceDest`, so PCA was applied to address this issue."
      ],
      "metadata": {
        "id": "qgwSUUpzIsQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Selecting the desired columns using square brackets\n",
        "high = df_balanced[['oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
        "pca = PCA(n_components=2) # number of components 2\n",
        "principal_components = pca.fit_transform(high)\n",
        "principal_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])"
      ],
      "metadata": {
        "id": "PmuA7ue8IyN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concat\n",
        "df_balanced.drop(['oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest'], axis=1, inplace=True)\n",
        "df_balanced = pd.concat([df_balanced, principal_df], axis=1)\n",
        "df_balanced.head()"
      ],
      "metadata": {
        "id": "x_fML2rrMZW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loadings = pca.components_.T  # Transpose to get variables as rows\n",
        "loading_df = pd.DataFrame(loadings, index=high.columns, columns=['PC1', 'PC2'])\n",
        "print(loading_df)"
      ],
      "metadata": {
        "id": "zUMdmCZyRSDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for correlation again\n",
        "corr = df_balanced.corr(numeric_only=True)\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(corr , annot =True)"
      ],
      "metadata": {
        "id": "QHFxH5AjzKpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# scaling"
      ],
      "metadata": {
        "id": "1a5m8WW798P4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaled_data = scaler.fit_transform(df_balanced)\n",
        "pd.DataFrame(scaled_data, columns=df_balanced.columns)"
      ],
      "metadata": {
        "id": "9VJMpORGT0eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Splitting & Modelling and Evaluation matrix"
      ],
      "metadata": {
        "id": "KfaeWo3b1ef4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "EthZ73851ijx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_balanced.drop(\"isFraud\", axis=1)\n",
        "Y = df_balanced[\"isFraud\"]\n",
        "\n",
        "# split the dataset for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= 0.2, random_state= 42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "metadata": {
        "id": "8Zf2GIvI0IV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LogisticRegression"
      ],
      "metadata": {
        "id": "RNjlyH_nQbd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "aj9RXgfk3bKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_r = LogisticRegression()\n",
        "log_r.fit(X_train, y_train)\n",
        "y_pred_lg = log_r.predict(X_test)"
      ],
      "metadata": {
        "id": "wPbrUPOE3ehj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred_lg))"
      ],
      "metadata": {
        "id": "xgLBBQ_N3jvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot confusuon matrix\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_lg), annot=True, fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FtRRSmfG4xMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBClassifier"
      ],
      "metadata": {
        "id": "6H02azYyPQNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# XGBoost\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "xgb_score = xgb.score(X_test, y_test) * 100\n",
        "print(\"XGBoost Classifier Accuracy:\", xgb_score)"
      ],
      "metadata": {
        "id": "FZ_STBV7PQUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred_xgb))"
      ],
      "metadata": {
        "id": "Y-lg_buEPpKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot confusuon matrix\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3yiAVOGBP4YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "* The XGBoost Classifier demonstrates high accuracy and a good balance between precision and recall in predicting fraudulent transactions.\n",
        "* It is effective in identifying a significant portion of actual fraud cases (high recall), while also minimizing false positives (reasonable precision).\n",
        "* The model might require further optimization to further reduce false positives, depending on the specific business context and the costs associated with false alarms.\n",
        "* Ongoing monitoring and evaluation are crucial to ensure the model's continued effectiveness in fraud detection.\n"
      ],
      "metadata": {
        "id": "eS978iIFRuxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importance"
      ],
      "metadata": {
        "id": "rMkcBpTb6jgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "result = permutation_importance(xgb, X_test, y_test, n_repeats=10, random_state=42)\n",
        "\n",
        "# Plotting permutation importance\n",
        "perm_sorted_idx = result.importances_mean.argsort()\n",
        "plt.barh(range(X_test.shape[1]), result.importances_mean[perm_sorted_idx])\n",
        "plt.yticks(range(X_test.shape[1]), X_test.columns[perm_sorted_idx])\n",
        "plt.xlabel(\"Mean Importance (Permuted)\")\n",
        "plt.title(\"Permutation Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6TYJY7n46jqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Findings\n",
        "\n",
        "1. `oldbalanceOrg` and `newbalanceOrig`: These features, representing the originator's balance before and after the transaction, have the highest permutation importance. This suggests that the model heavily relies on changes in the originator's account balance to identify fraudulent activities. This is logical as fraudulent transactions often involve significant withdrawals or transfers, leading to noticeable changes in the account balance.\n",
        "2. `amount:` The transaction amount is another crucial feature. Large or unusual transaction amounts can be indicative of fraudulent behavior, and the model seems to have learned this pattern.\n",
        "3. `nameDest` and `nameOrig`: While not as important as the balance and amount features, these features (encoded representations of the recipient and originator's names) also contribute to the model's predictions. This might reflect patterns where certain accounts or individuals are more frequently involved in fraudulent transactions.\n",
        "4. Other Features: The remaining features, such as `step`, `type`, `oldbalanceDest`, and `newbalanceDest`, have relatively lower importance. This doesn't mean they are completely irrelevant, but their impact on the model's predictions is less significant compared to the top features.\n",
        "---\n",
        "# Implications for Fraud Detection\n",
        "\n",
        "- **Focus on Balance and Amount:** The results emphasize the importance of monitoring changes in account balances and transaction amounts for fraud detection. Real-time systems that flag unusual patterns in these features could be valuable in preventing fraudulent activities.\n",
        "\n",
        "- **Investigate Suspicious Accounts:** The importance of nameDest and nameOrig suggests that identifying and monitoring accounts frequently associated with fraud could be an effective strategy.\n",
        "Contextual Information: While step and type have lower importance, they still provide valuable contextual information. Combining these features with the more important ones could improve the accuracy and interpretability of fraud detection models.\n",
        "- **Further Feature Engineering:** It might be beneficial to explore new features derived from existing data, such as transaction velocity, daily spending limits, or time-based features, to enhance the model's performance.\n",
        "Overall, the permutation importance analysis for this dataset highlights the key features that drive the model's predictions and provides valuable insights for improving fraud detection strategies. By focusing on these important features and incorporating contextual information, we can develop more robust and effective systems to combat fraud."
      ],
      "metadata": {
        "id": "M0taSwnN7nU1"
      }
    }
  ]
}